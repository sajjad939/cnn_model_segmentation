# -*- coding: utf-8 -*-
"""cnnfyp model training.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cDGmK1js0MpvEfnOroEKtfeX926gyI_H
"""

# Step 2: Upload your zip file (containing 'images/' and 'masks/')
from google.colab import files
uploaded = files.upload()

# Step 2: Unzip the uploaded file (whatever the structure is)
import zipfile, os

zip_file = next(iter(uploaded))  # First uploaded file
extract_dir = "raw_dataset"

with zipfile.ZipFile(zip_file, 'r') as zip_ref:
    zip_ref.extractall(extract_dir)

print("âœ… Extracted to:", extract_dir)



# Step 3: Unzip and prepare folders
import zipfile
import os

# Unzip the uploaded file
import zipfile
zip_path = list(uploaded.keys())[0]  # get uploaded zip filename
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall("raw_dataset")

# Show contents to verify
os.listdir("raw_dataset")

# Step 3: Automatically find 'images' and 'masks' folders
image_dir = None
mask_dir = None

for root, dirs, files in os.walk(extract_dir):
    for d in dirs:
        d_path = os.path.join(root, d)
        if 'image' in d.lower():
            image_dir = d_path
        elif 'mask' in d.lower():
            mask_dir = d_path

print("âœ… Found folders:")
print("Images:", image_dir)
print("Masks:", mask_dir)

# Step 3: Automatically find 'images' and 'masks' folders
image_dir = None
mask_dir = None

for root, dirs, files in os.walk(extract_dir):
    for d in dirs:
        d_path = os.path.join(root, d)
        if 'image' in d.lower():
            image_dir = d_path
        elif 'mask' in d.lower():
            mask_dir = d_path

print("âœ… Found folders:")
print("Images:", image_dir)
print("Masks:", mask_dir)

# Step 4: Resize and save to clean format
from PIL import Image
import shutil

output_dir = 'resized_dataset'
resized_images_dir = os.path.join(output_dir, 'images')
resized_masks_dir = os.path.join(output_dir, 'masks')

os.makedirs(resized_images_dir, exist_ok=True)
os.makedirs(resized_masks_dir, exist_ok=True)

def resize_images(input_dir, output_dir, size=(128, 128)):
    for filename in os.listdir(input_dir):
        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):
            img = Image.open(os.path.join(input_dir, filename)).convert('RGB')
            img = img.resize(size)
            img.save(os.path.join(output_dir, filename))

resize_images(image_dir, resized_images_dir)
resize_images(mask_dir, resized_masks_dir)

print("âœ… Resizing completed and saved to:", output_dir)

# Step 5: Zip and download the resized dataset
shutil.make_archive("resized_dataset", 'zip', output_dir)

from google.colab import files
files.download("resized_dataset.zip")



# Step 5: Zip the resized dataset for download
import shutil

shutil.make_archive("resized_dataset", 'zip', output_dir)

pip install tensorflow numpy scikit-learn matplotlib

# âœ… Imports
import os
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow.keras import layers, models

# --- PARAMETERS ---
IMG_HEIGHT = 128
IMG_WIDTH = 128
IMG_CHANNELS = 3
DATASET_PATH = '/content/resized_dataset'

def load_dataset():
    image_dir = os.path.join(DATASET_PATH, 'images')
    mask_dir = os.path.join(DATASET_PATH, 'masks')

    image_files = sorted(os.listdir(image_dir))
    mask_files = sorted(os.listdir(mask_dir))

    images = []
    masks = []

    for img_name, mask_name in zip(image_files, mask_files):
        img = load_img(os.path.join(image_dir, img_name), target_size=(IMG_HEIGHT, IMG_WIDTH))
        img = img_to_array(img) / 255.0
        images.append(img)

        mask = load_img(os.path.join(mask_dir, mask_name), color_mode='grayscale', target_size=(IMG_HEIGHT, IMG_WIDTH))
        mask = img_to_array(mask) / 255.0
        mask = (mask > 0.5).astype(np.float32)  # Ensure binary mask
        masks.append(mask)

    return np.array(images), np.array(masks)

# âœ… Load dataset
X, y = load_dataset()
print(f"Images shape: {X.shape}, Masks shape: {y.shape}")

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

import os
import cv2
import numpy as np
from sklearn.model_selection import train_test_split
from PIL import Image

# --- CONFIG ---
dataset_folder = '/content/raw_dataset/New folder (2)'  # Folder with all raw images
output_folder = '/content/unet_dataset'
IMG_HEIGHT = 128
IMG_WIDTH = 128

# --- Create output directories ---
def create_output_dirs():
    for split in ['train', 'val', 'test']:
        for subfolder in ['images', 'masks']:
            os.makedirs(os.path.join(output_folder, split, subfolder), exist_ok=True)

# --- Generate mask from image (using color thresholding) ---
def generate_mask(image):
    # Convert to HSV for better color segmentation
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

    # Example: mask for white cotton (tune thresholds as needed)
    lower_white = np.array([0, 0, 200])
    upper_white = np.array([180, 55, 255])
    mask = cv2.inRange(hsv, lower_white, upper_white)

    return mask

# --- Resize and save ---
def save_resized(image, mask, img_save_path, mask_save_path):
    image = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))
    mask = cv2.resize(mask, (IMG_WIDTH, IMG_HEIGHT))

    cv2.imwrite(img_save_path, image)
    cv2.imwrite(mask_save_path, mask)

# --- Main processing ---
def process_and_split():
    create_output_dirs()

    all_filenames = sorted([f for f in os.listdir(dataset_folder) if f.endswith(('.jpg', '.png'))])
    train_files, temp_files = train_test_split(all_filenames, test_size=0.3, random_state=42)
    val_files, test_files = train_test_split(temp_files, test_size=0.5, random_state=42)

    dataset = {
        'train': train_files,
        'val': val_files,
        'test': test_files
    }

    for split, files in dataset.items():
        for filename in files:
            img_path = os.path.join(dataset_folder, filename)
            image = cv2.imread(img_path)

            if image is None:
                print(f"Error loading image: {filename}")
                continue

            mask = generate_mask(image)

            # Define save paths
            img_save_path = os.path.join(output_folder, split, 'images', filename)
            mask_save_path = os.path.join(output_folder, split, 'masks', filename)

            save_resized(image, mask, img_save_path, mask_save_path)

    print("âœ… All images processed, masks generated, and dataset split successfully.")

# --- Run it ---
process_and_split()

import os
import numpy as np
import matplotlib.pyplot as plt
import cv2
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import img_to_array, load_img
from tensorflow.keras import layers, models
import tensorflow as tf

# --- PARAMETERS ---
IMG_HEIGHT = 128
IMG_WIDTH = 128
IMG_CHANNELS = 3
RAW_IMAGE_DIR = '/content/raw_dataset/New folder (2)'  # Your folder with raw images
DATASET_PATH = '/content/resized_dataset'

# --- Create folders ---
def create_dataset_folders():
    os.makedirs(os.path.join(DATASET_PATH, 'images'), exist_ok=True)
    os.makedirs(os.path.join(DATASET_PATH, 'masks'), exist_ok=True)

# --- Generate binary mask (based on white color) ---
def generate_mask(image):
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    lower_white = np.array([0, 0, 200])
    upper_white = np.array([180, 40, 255])
    mask = cv2.inRange(hsv, lower_white, upper_white)
    return mask

# --- Preprocess and save all images + masks ---
def preprocess_and_save():
    create_dataset_folders()
    image_files = sorted([f for f in os.listdir(RAW_IMAGE_DIR) if f.endswith(('.png', '.jpg'))])

    for file in image_files:
        img_path = os.path.join(RAW_IMAGE_DIR, file)
        image = cv2.imread(img_path)
        if image is None:
            continue

        mask = generate_mask(image)

        image = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))
        mask = cv2.resize(mask, (IMG_WIDTH, IMG_HEIGHT))

        img_save_path = os.path.join(DATASET_PATH, 'images', file)
        mask_save_path = os.path.join(DATASET_PATH, 'masks', file)

        cv2.imwrite(img_save_path, image)
        cv2.imwrite(mask_save_path, mask)

    print("âœ… Images and masks processed and saved.")

# --- LOAD IMAGES AND MASKS ---
def load_dataset():
    image_dir = os.path.join(DATASET_PATH, 'images')
    mask_dir = os.path.join(DATASET_PATH, 'masks')

    image_files = sorted(os.listdir(image_dir))
    mask_files = sorted(os.listdir(mask_dir))

    images = []
    masks = []

    for img_name, mask_name in zip(image_files, mask_files):
        img = load_img(os.path.join(image_dir, img_name), target_size=(IMG_HEIGHT, IMG_WIDTH))
        img = img_to_array(img) / 255.0
        images.append(img)

        mask = load_img(os.path.join(mask_dir, mask_name), color_mode='grayscale', target_size=(IMG_HEIGHT, IMG_WIDTH))
        mask = img_to_array(mask) / 255.0
        mask = (mask > 0.5).astype(np.float32)  # Ensure binary mask
        masks.append(mask)

    return np.array(images), np.array(masks)

# --- U-NET MODEL ---
def unet_model(input_size=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)):
    inputs = layers.Input(input_size)

    # Encoder
    c1 = layers.Conv2D(16, 3, activation='relu', padding='same')(inputs)
    c1 = layers.Conv2D(16, 3, activation='relu', padding='same')(c1)
    p1 = layers.MaxPooling2D()(c1)

    c2 = layers.Conv2D(32, 3, activation='relu', padding='same')(p1)
    c2 = layers.Conv2D(32, 3, activation='relu', padding='same')(c2)
    p2 = layers.MaxPooling2D()(c2)

    c3 = layers.Conv2D(64, 3, activation='relu', padding='same')(p2)
    c3 = layers.Conv2D(64, 3, activation='relu', padding='same')(c3)
    p3 = layers.MaxPooling2D()(c3)

    # Bottleneck
    c4 = layers.Conv2D(128, 3, activation='relu', padding='same')(p3)
    c4 = layers.Conv2D(128, 3, activation='relu', padding='same')(c4)

    # Decoder
    u5 = layers.UpSampling2D()(c4)
    u5 = layers.concatenate([u5, c3])
    c5 = layers.Conv2D(64, 3, activation='relu', padding='same')(u5)
    c5 = layers.Conv2D(64, 3, activation='relu', padding='same')(c5)

    u6 = layers.UpSampling2D()(c5)
    u6 = layers.concatenate([u6, c2])
    c6 = layers.Conv2D(32, 3, activation='relu', padding='same')(u6)
    c6 = layers.Conv2D(32, 3, activation='relu', padding='same')(c6)

    u7 = layers.UpSampling2D()(c6)
    u7 = layers.concatenate([u7, c1])
    c7 = layers.Conv2D(16, 3, activation='relu', padding='same')(u7)
    c7 = layers.Conv2D(16, 3, activation='relu', padding='same')(c7)

    outputs = layers.Conv2D(1, 1, activation='sigmoid')(c7)

    return models.Model(inputs, outputs)

# --- RUN ALL STEPS ---
preprocess_and_save()
X, y = load_dataset()
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

model = unet_model()
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# --- TRAINING ---
history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    batch_size=8,
    epochs=15
)

# --- PLOT ACCURACY ---
plt.plot(history.history['accuracy'], label='Train Acc')
plt.plot(history.history['val_accuracy'], label='Val Acc')
plt.legend()
plt.title("Model Accuracy")
plt.show()

# --- PREDICT AND VISUALIZE ---
def show_predictions(X, y_true, model, count=5):
    preds = model.predict(X[:count])
    for i in range(count):
        plt.figure(figsize=(12, 3))
        plt.subplot(1, 3, 1)
        plt.imshow(X[i])
        plt.title("Image")
        plt.subplot(1, 3, 2)
        plt.imshow(y_true[i].squeeze(), cmap='gray')
        plt.title("Ground Truth")
        plt.subplot(1, 3, 3)
        plt.imshow(preds[i].squeeze(), cmap='gray')
        plt.title("Prediction")
        plt.show()

show_predictions(X_val, y_val, model)

from sklearn.metrics import precision_score, recall_score, f1_score
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# --- EVALUATION METRICS ---
def evaluate_model(X, y_true, model):
    preds = model.predict(X)
    preds = (preds > 0.5).astype(np.uint8)  # Binarize predictions

    y_true_flat = y_true.flatten()
    preds_flat = preds.flatten()

    precision = precision_score(y_true_flat, preds_flat)
    recall = recall_score(y_true_flat, preds_flat)
    f1 = f1_score(y_true_flat, preds_flat)

    print(f"ðŸ“ˆ Precision: {precision:.4f}")
    print(f"ðŸ“ˆ Recall: {recall:.4f}")
    print(f"ðŸ“ˆ F1 Score: {f1:.4f}")

    return precision, recall, f1

# --- CALL METRIC FUNCTION ---
precision, recall, f1 = evaluate_model(X_val, y_val, model)

# --- PLOT METRICS ---
plt.figure(figsize=(6, 4))
metrics = [precision, recall, f1]
names = ['Precision', 'Recall', 'F1-Score']
plt.bar(names, metrics, color=['skyblue', 'lightgreen', 'salmon'])
plt.title("Evaluation Metrics on Validation Set")
plt.ylim(0, 1)
plt.ylabel("Score")
for i, v in enumerate(metrics):
    plt.text(i, v + 0.02, f"{v:.2f}", ha='center', fontweight='bold')
plt.show()

# --- EVALUATION METRICS + CONFUSION MATRIX ---
def evaluate_model(X, y_true, model):
    preds = model.predict(X)
    preds = (preds > 0.5).astype(np.uint8)  # Binarize predictions

    y_true_flat = y_true.flatten()
    preds_flat = preds.flatten()

    # Metrics
    precision = precision_score(y_true_flat, preds_flat)
    recall = recall_score(y_true_flat, preds_flat)
    f1 = f1_score(y_true_flat, preds_flat)

    print(f"ðŸ“ˆ Precision: {precision:.4f}")
    print(f"ðŸ“ˆ Recall: {recall:.4f}")
    print(f"ðŸ“ˆ F1 Score: {f1:.4f}")

    # Confusion Matrix
    cm = confusion_matrix(y_true_flat, preds_flat)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Background (0)", "Cotton (1)"])
    disp.plot(cmap='Blues', values_format='d')
    plt.title("Confusion Matrix")
    plt.show()

    return precision, recall, f1, cm

# Call it
precision, recall, f1, cm = evaluate_model(X_val, y_val, model)

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay

def evaluate_model(X, y_true, model, title="Validation"):
    preds = model.predict(X)
    preds = (preds > 0.5).astype(np.uint8)

    y_true_flat = y_true.flatten()
    preds_flat = preds.flatten()

    acc = np.mean(preds_flat == y_true_flat)
    precision = precision_score(y_true_flat, preds_flat)
    recall = recall_score(y_true_flat, preds_flat)
    f1 = f1_score(y_true_flat, preds_flat)

    print(f"ðŸ“Š Evaluation on {title} Set:")
    print(f"âœ… Accuracy:  {acc:.4f}")
    print(f"âœ… Precision: {precision:.4f}")
    print(f"âœ… Recall:    {recall:.4f}")
    print(f"âœ… F1 Score:  {f1:.4f}")

    # Confusion Matrix
    cm = confusion_matrix(y_true_flat, preds_flat)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Background (0)", "Cotton (1)"])
    disp.plot(cmap='Blues', values_format='d')
    plt.title(f"{title} Confusion Matrix")
    plt.show()

    return acc, precision, recall, f1

# Evaluate on Training Set
train_acc, train_precision, train_recall, train_f1 = evaluate_model(X_train, y_train, model, title="Training")

# Evaluate on Validation Set
val_acc, val_precision, val_recall, val_f1 = evaluate_model(X_val, y_val, model, title="Validation")

# Comparison Plot
metrics_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score']
train_metrics = [train_acc, train_precision, train_recall, train_f1]
val_metrics = [val_acc, val_precision, val_recall, val_f1]

x = np.arange(len(metrics_names))
width = 0.35

plt.figure(figsize=(8, 5))
plt.bar(x - width/2, train_metrics, width, label='Train', color='lightblue')
plt.bar(x + width/2, val_metrics, width, label='Validation', color='salmon')

plt.xticks(x, metrics_names)
plt.ylim(0, 1)
plt.title('Training vs Validation Metrics')
plt.ylabel('Score')
plt.legend()
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.show()

# --- SAVE MODEL AS .h5 ---
model.save("unet_model.h5")
print("âœ… Model saved as unet_model.h5")

import cv2
import numpy as np
from tensorflow.keras.models import load_model

# --- PARAMETERS ---
IMG_HEIGHT = 128
IMG_WIDTH = 128

# --- Load the trained model (.h5) ---
model = load_model("/content/unet_model.h5")

# --- Start webcam ---
cap = cv2.VideoCapture(0)  # Use 0 for default webcam

if not cap.isOpened():
    print("âŒ Could not open webcam.")
    exit()

while True:
    ret, frame = cap.read()
    if not ret:
        print("âŒ Failed to grab frame.")
        break

    # Resize and preprocess input
    resized = cv2.resize(frame, (IMG_WIDTH, IMG_HEIGHT))
    input_img = resized.astype(np.float32) / 255.0
    input_img = np.expand_dims(input_img, axis=0)  # Add batch dimension

    # Predict mask
    pred_mask = model.predict(input_img)[0]
    mask = (pred_mask.squeeze() > 0.5).astype(np.uint8) * 255  # Binary mask

    # Resize mask to original frame size for display
    mask_resized = cv2.resize(mask, (frame.shape[1], frame.shape[0]))

    # Convert to 3-channel for overlay
    mask_color = cv2.cvtColor(mask_resized, cv2.COLOR_GRAY2BGR)

    # Overlay mask on original frame (optional)
    overlay = cv2.addWeighted(frame, 0.7, mask_color, 0.3, 0)

    # Show both original + mask
    cv2.imshow("Webcam - Original", frame)
    cv2.imshow("Webcam - Mask", mask_resized)
    cv2.imshow("Webcam - Overlay", overlay)

    # Exit on 'q'
    if cv2.waitKey(1) & 0xFF == ord("q"):
        break

# --- Cleanup ---
cap.release()
cv2.destroyAllWindows()

import tensorflow as tf

# Load your trained .h5 model
model = tf.keras.models.load_model('unet_model.h5')

# Convert to .tflite
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

# Save .tflite model
with open('unet_model.tflite', 'wb') as f:
    f.write(tflite_model)

print("âœ… Model converted and saved as unet_model.tflite")

from google.colab import files
files.download('/content/unet_model.tflite')

# Zip your folder
!zip -r unet_segmentation_project.zip unet_segmentation_project
from google.colab import files
files.download("unet_segmentation_project.zip")